{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f62f6fe",
   "metadata": {},
   "source": [
    "## 2. Creating Sample Data\n",
    "\n",
    "Let's create some sample text data to work with. In a real scenario, you would load your own dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4678863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample documents for our preprocessing pipeline\n",
    "print(\"üìù Creating sample data...\")\n",
    "\n",
    "# Sample text documents of varying quality and topics\n",
    "sample_documents = [\n",
    "    {\n",
    "        \"text\": \"Machine learning is a subset of artificial intelligence that enables computers to learn and make decisions from data without being explicitly programmed. It has applications in image recognition, natural language processing, and predictive analytics.\",\n",
    "        \"source\": \"ml_article_1\",\n",
    "        \"domain\": \"technology\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"The quick brown fox jumps over the lazy dog. This is a common pangram used for typing practice.\",\n",
    "        \"source\": \"example_1\", \n",
    "        \"domain\": \"general\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Deep learning neural networks have revolutionized computer vision tasks. Convolutional neural networks can extract hierarchical features from images, enabling breakthrough performance in object detection and image classification.\",\n",
    "        \"source\": \"dl_article_1\",\n",
    "        \"domain\": \"technology\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"lorem ipsum dolor sit amet consectetur adipiscing elit sed do eiusmod tempor\",\n",
    "        \"source\": \"filler_1\",\n",
    "        \"domain\": \"placeholder\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Natural language processing involves the interaction between computers and human language. Modern NLP systems use transformer architectures to understand context and generate human-like text responses.\",\n",
    "        \"source\": \"nlp_article_1\", \n",
    "        \"domain\": \"technology\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"The weather today is sunny with a temperature of 75 degrees Fahrenheit. Perfect for outdoor activities and spending time in the park.\",\n",
    "        \"source\": \"weather_1\",\n",
    "        \"domain\": \"general\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Quantum computing leverages quantum mechanical phenomena to process information in fundamentally different ways than classical computers. Quantum bits or qubits can exist in superposition states.\",\n",
    "        \"source\": \"quantum_1\",\n",
    "        \"domain\": \"technology\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"The quick brown fox jumps over the lazy dog. This is a common pangram used for typing practice.\",  # Duplicate\n",
    "        \"source\": \"example_2\",\n",
    "        \"domain\": \"general\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Data science combines statistics, programming, and domain expertise to extract insights from large datasets. It involves data collection, cleaning, analysis, and visualization.\",\n",
    "        \"source\": \"ds_article_1\",\n",
    "        \"domain\": \"technology\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"a b c d e f g h i j k l m n o p q r s t u v w x y z\",  # Low quality\n",
    "        \"source\": \"alphabet_1\",\n",
    "        \"domain\": \"test\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create a temporary directory for our data\n",
    "data_dir = Path(\"./temp_preprocessing_data\")\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save as JSONL (JSON Lines) format\n",
    "import jsonlines\n",
    "\n",
    "jsonl_file = data_dir / \"sample_documents.jsonl\"\n",
    "with jsonlines.open(jsonl_file, 'w') as writer:\n",
    "    for doc in sample_documents:\n",
    "        writer.write(doc)\n",
    "\n",
    "print(f\"‚úÖ Created {len(sample_documents)} sample documents\")\n",
    "print(f\"üìÅ Saved to: {jsonl_file}\")\n",
    "print(f\"üìä Sample document preview:\")\n",
    "for i, doc in enumerate(sample_documents[:3]):\n",
    "    print(f\"   {i+1}. {doc['text'][:80]}...\" if len(doc['text']) > 80 else f\"   {i+1}. {doc['text']}\")\n",
    "\n",
    "# Also create some CSV data for variety\n",
    "csv_file = data_dir / \"sample_documents.csv\"\n",
    "df = pd.DataFrame(sample_documents)\n",
    "df.to_csv(csv_file, index=False)\n",
    "print(f\"üìÑ Also saved as CSV: {csv_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b41cb40",
   "metadata": {},
   "source": [
    "# NeMo Curator: Complete Guide to Preprocessing, Embeddings, and Vector Storage\n",
    "\n",
    "This comprehensive tutorial will guide you through the complete pipeline of preprocessing data, generating embeddings, and storing vectors for retrieval applications using NVIDIA NeMo Curator.\n",
    "\n",
    "## üéØ What You'll Learn\n",
    "\n",
    "1. **Environment Setup** - Configure NeMo Curator with GPU acceleration\n",
    "2. **Data Loading & Preprocessing** - Clean and prepare raw text data\n",
    "3. **Document Chunking** - Optimize text segmentation for embeddings\n",
    "4. **Embedding Generation** - Create high-quality text embeddings at scale\n",
    "5. **Vector Storage** - Set up efficient vector databases for retrieval\n",
    "6. **Similarity Search** - Implement and test retrieval systems\n",
    "7. **Performance Optimization** - Scale and optimize your pipeline\n",
    "\n",
    "## üöÄ Prerequisites\n",
    "\n",
    "- NVIDIA GPU with CUDA support\n",
    "- Python 3.8+ \n",
    "- NeMo Curator installed with GPU acceleration\n",
    "- Basic familiarity with text processing concepts\n",
    "\n",
    "Let's get started building your preprocessing and embedding pipeline!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60fe991",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Dependencies\n",
    "\n",
    "First, let's install and configure all necessary libraries for our preprocessing and embedding pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c76383c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Setting up imports from source...\n",
      "‚úÖ Core NeMo Curator imports successful!\n",
      "‚ö†Ô∏è  Semantic dedup modules not available: No module named 'cudf'\n",
      "‚úÖ Text processing modules imported!\n",
      "‚úÖ Progress tracking available!\n",
      "‚úÖ All imports configured!\n",
      "‚ö†Ô∏è  CUDA not available, using CPU\n",
      "‚ö†Ô∏è  GPU acceleration not available, using CPU backend\n",
      "\n",
      "üéØ System Capabilities Summary:\n",
      "   - GPU Available: False\n",
      "   - GPU Acceleration: False\n",
      "   - Semantic Dedup: False\n",
      "   - Ready for preprocessing pipeline: ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "# Setup for NeMo Curator from source\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add the Curator directory to Python path since we're running from source\n",
    "curator_path = \"/Users/productpat/Curator\"\n",
    "if curator_path not in sys.path:\n",
    "    sys.path.insert(0, curator_path)\n",
    "\n",
    "print(\"üîß Setting up imports from source...\")\n",
    "\n",
    "try:\n",
    "    # Core NeMo Curator imports\n",
    "    from nemo_curator.datasets import DocumentDataset\n",
    "    from nemo_curator.utils.distributed_utils import get_client, get_num_workers\n",
    "    from nemo_curator.modules import (\n",
    "        AddId, \n",
    "        ExactDuplicates, \n",
    "        FuzzyDuplicates,\n",
    "        Sequential\n",
    "    )\n",
    "    print(\"‚úÖ Core NeMo Curator imports successful!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Failed to import core NeMo Curator: {e}\")\n",
    "\n",
    "try:\n",
    "    # Import semantic dedup modules directly from files\n",
    "    from nemo_curator.modules.semantic_dedup.semdedup import SemDedup\n",
    "    from nemo_curator.modules.semantic_dedup.embeddings import EmbeddingCreator\n",
    "    print(\"‚úÖ Semantic deduplication modules imported!\")\n",
    "    SEMDEDUP_AVAILABLE = True\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è  Semantic dedup modules not available: {e}\")\n",
    "    SEMDEDUP_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    # Text processing imports\n",
    "    from nemo_curator.modifiers import UnicodeReformatter\n",
    "    from nemo_curator.filters import FastTextLangId\n",
    "    from nemo_curator import Modify, ScoreFilter\n",
    "    print(\"‚úÖ Text processing modules imported!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è  Text processing modules not available: {e}\")\n",
    "\n",
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from pathlib import Path\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "    print(\"‚úÖ Progress tracking available!\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è  tqdm not available, progress bars disabled\")\n",
    "    tqdm = lambda x: x  # Simple fallback\n",
    "\n",
    "print(\"‚úÖ All imports configured!\")\n",
    "\n",
    "# Check GPU availability\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"‚úÖ CUDA available: {torch.cuda.device_count()} GPU(s)\")\n",
    "        print(f\"   Current device: {torch.cuda.get_device_name()}\")\n",
    "        USE_GPU = True\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  CUDA not available, using CPU\")\n",
    "        USE_GPU = False\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è  PyTorch not available\")\n",
    "    USE_GPU = False\n",
    "\n",
    "# Check if cuDF is available for GPU acceleration\n",
    "try:\n",
    "    import cudf\n",
    "    print(\"‚úÖ GPU acceleration (cuDF) available\")\n",
    "    GPU_ACCELERATION = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è  GPU acceleration not available, using CPU backend\")\n",
    "    GPU_ACCELERATION = False\n",
    "\n",
    "print(f\"\\nüéØ System Capabilities Summary:\")\n",
    "print(f\"   - GPU Available: {USE_GPU}\")\n",
    "print(f\"   - GPU Acceleration: {GPU_ACCELERATION}\")\n",
    "print(f\"   - Semantic Dedup: {SEMDEDUP_AVAILABLE}\")\n",
    "print(f\"   - Ready for preprocessing pipeline: ‚úÖ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3944ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Initializing distributed computing environment...\n",
      "‚ö†Ô∏è  GPU cluster failed, falling back to CPU: dask_cuda.LocalCUDACluster is not enabled in non GPU-enabled installations or environments. Install GPU packages via `pip install --extra-index-url https://pypi.nvidia.com nemo-curator[cuda12x]`\n",
      "or use `pip install --extra-index-url https://pypi.nvidia.com \".[cuda12x]\"` if installing from source\n",
      "‚úÖ CPU cluster initialized with 4 workers\n",
      "‚ö†Ô∏è  GPU acceleration not available, using CPU backend\n",
      "‚úÖ CPU cluster initialized with 4 workers\n",
      "‚ö†Ô∏è  GPU acceleration not available, using CPU backend\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-3d5e7cd0-6a88-11f0-9223-acde48001122</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> distributed.LocalCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:8787/status\" target=\"_blank\">http://127.0.0.1:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">LocalCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">d2926bfa</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:8787/status\" target=\"_blank\">http://127.0.0.1:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 4\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 4\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 29.80 GiB\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "    <td style=\"text-align: left;\"><strong>Status:</strong> running</td>\n",
       "    <td style=\"text-align: left;\"><strong>Using processes:</strong> True</td>\n",
       "</tr>\n",
       "\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-af0d691b-d8df-4870-8207-50b0fe360ad3</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://127.0.0.1:59016\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 0 \n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:8787/status\" target=\"_blank\">http://127.0.0.1:8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 0 B\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 0</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:59030\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:59034/status\" target=\"_blank\">http://127.0.0.1:59034/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 7.45 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:59019\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /var/folders/wb/q2j_ggdd1l37479y1w2_cbcm0000gn/T/dask-scratch-space/worker-v1bnf0fy\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 1</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:59028\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:59033/status\" target=\"_blank\">http://127.0.0.1:59033/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 7.45 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:59021\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /var/folders/wb/q2j_ggdd1l37479y1w2_cbcm0000gn/T/dask-scratch-space/worker-vvz5zh2a\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 2</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:59029\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:59032/status\" target=\"_blank\">http://127.0.0.1:59032/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 7.45 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:59023\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /var/folders/wb/q2j_ggdd1l37479y1w2_cbcm0000gn/T/dask-scratch-space/worker-u9b530ho\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 3</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:59027\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:59031/status\" target=\"_blank\">http://127.0.0.1:59031/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 7.45 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:59025\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /var/folders/wb/q2j_ggdd1l37479y1w2_cbcm0000gn/T/dask-scratch-space/worker-l_uwyao9\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:59016' processes=4 threads=4, memory=29.80 GiB>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize GPU-accelerated Dask client for distributed processing\n",
    "print(\"üöÄ Initializing distributed computing environment...\")\n",
    "\n",
    "try:\n",
    "    # Start GPU cluster for semantic deduplication and embeddings\n",
    "    client = get_client(cluster_type=\"gpu\", set_torch_to_use_rmm=False)\n",
    "    print(f\"‚úÖ GPU cluster initialized with {get_num_workers(client)} workers\")\n",
    "    print(f\"Dashboard link: {client.dashboard_link}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  GPU cluster failed, falling back to CPU: {e}\")\n",
    "    # Fallback to CPU cluster\n",
    "    client = get_client(cluster_type=\"cpu\", n_workers=4, processes=True, memory_limit=\"8GB\")\n",
    "    print(f\"‚úÖ CPU cluster initialized with {get_num_workers(client)} workers\")\n",
    "\n",
    "# Check GPU availability\n",
    "try:\n",
    "    import cudf\n",
    "    print(\"‚úÖ GPU acceleration (cuDF) available\")\n",
    "    USE_GPU = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è  GPU acceleration not available, using CPU backend\")\n",
    "    USE_GPU = False\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9063aa15",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Initial Preprocessing\n",
    "\n",
    "Let's start by loading and validating our raw data. NeMo Curator supports various input formats including JSONL, Parquet, and plain text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c4839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data directory and files for this tutorial\n",
    "data_dir = Path(\"tutorial_data\")\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Create sample documents for our tutorial\n",
    "sample_documents = [\n",
    "    {\n",
    "        \"text\": \"Natural language processing (NLP) is a subfield of artificial intelligence that focuses on the interaction between computers and human language. It involves developing algorithms and models that can understand, interpret, and generate human language.\",\n",
    "        \"source\": \"AI_encyclopedia\",\n",
    "        \"category\": \"technology\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Machine learning is a method of data analysis that automates analytical model building. It uses algorithms that iteratively learn from data, allowing computers to find hidden insights without being explicitly programmed where to look.\",\n",
    "        \"source\": \"ML_handbook\", \n",
    "        \"category\": \"technology\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Climate change refers to long-term shifts in global or regional climate patterns. The primary cause is increased levels of greenhouse gases produced by human activities, particularly the burning of fossil fuels.\",\n",
    "        \"source\": \"climate_report\",\n",
    "        \"category\": \"environment\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Quantum computing leverages quantum mechanical phenomena like superposition and entanglement to process information in fundamentally different ways than classical computers. This enables solving certain complex problems exponentially faster.\",\n",
    "        \"source\": \"quantum_physics\",\n",
    "        \"category\": \"technology\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Biodiversity refers to the variety of life on Earth, including the variety of species, ecosystems, and genetic diversity within species. It is essential for ecosystem stability and human well-being.\",\n",
    "        \"source\": \"biology_textbook\",\n",
    "        \"category\": \"environment\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Save sample data as JSONL\n",
    "sample_file = data_dir / \"sample_documents.jsonl\"\n",
    "with open(sample_file, 'w') as f:\n",
    "    for doc in sample_documents:\n",
    "        f.write(json.dumps(doc) + '\\n')\n",
    "\n",
    "print(f\"‚úÖ Created sample data: {sample_file}\")\n",
    "print(f\"üìÑ Number of documents: {len(sample_documents)}\")\n",
    "\n",
    "# Display first document\n",
    "print(f\"üìã Sample document:\")\n",
    "print(json.dumps(sample_documents[0], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39720e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data using NeMo Curator's DocumentDataset\n",
    "print(\"üìö Loading data with NeMo Curator...\")\n",
    "\n",
    "# Method 1: Load from JSONL files\n",
    "backend = \"cudf\" if USE_GPU else \"pandas\"\n",
    "dataset = DocumentDataset.read_json(str(data_dir), backend=backend)\n",
    "\n",
    "print(f\"‚úÖ Dataset loaded successfully!\")\n",
    "print(f\"üìä Dataset info:\")\n",
    "print(f\"   - Number of partitions: {dataset.df.npartitions}\")\n",
    "print(f\"   - Backend: {backend}\")\n",
    "print(f\"   - Columns: {list(dataset.df.columns)}\")\n",
    "\n",
    "# Display basic statistics\n",
    "df_sample = dataset.df.head()\n",
    "print(f\"\\nüìã First few documents:\")\n",
    "print(df_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c691b41",
   "metadata": {},
   "source": [
    "## 3. Text Cleaning and Normalization\n",
    "\n",
    "Before generating embeddings, we need to clean and normalize our text data. This includes Unicode normalization, removing unwanted characters, and filtering by language quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edb9426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add unique document IDs first\n",
    "print(\"üè∑Ô∏è  Adding unique document IDs...\")\n",
    "add_id = AddId(id_field=\"doc_id\", id_prefix=\"doc\", start_index=0)\n",
    "dataset_with_ids = add_id(dataset)\n",
    "\n",
    "print(f\"‚úÖ Added IDs. Sample with ID:\")\n",
    "print(dataset_with_ids.df.head(2).compute())\n",
    "\n",
    "# Unicode normalization to handle various text encodings\n",
    "print(\"\\nüßπ Applying Unicode normalization...\")\n",
    "unicode_normalizer = UnicodeReformatter()\n",
    "normalize_step = Modify(unicode_normalizer)\n",
    "normalized_dataset = normalize_step(dataset_with_ids)\n",
    "\n",
    "print(\"‚úÖ Unicode normalization complete\")\n",
    "\n",
    "# Check for text improvements\n",
    "original_sample = dataset_with_ids.df.head(1)['text'].compute().iloc[0]\n",
    "normalized_sample = normalized_dataset.df.head(1)['text'].compute().iloc[0]\n",
    "\n",
    "print(f\"\\nüìù Text normalization example:\")\n",
    "print(f\"Original: {original_sample[:100]}...\")\n",
    "print(f\"Normalized: {normalized_sample[:100]}...\")\n",
    "\n",
    "print(f\"\\nüìä Dataset size after normalization: {len(normalized_dataset.df)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8c4494",
   "metadata": {},
   "source": [
    "## 4. Document Chunking and Segmentation\n",
    "\n",
    "For effective embedding generation, we need to split long documents into smaller, semantically coherent chunks. This is crucial for retrieval applications where you want to find specific relevant passages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b684a2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import document splitting modules\n",
    "from nemo_curator.modules import DocumentSplitter, DocumentJoiner\n",
    "\n",
    "print(\"‚úÇÔ∏è  Setting up document chunking pipeline...\")\n",
    "\n",
    "# For this example, let's create some longer documents to demonstrate chunking\n",
    "longer_docs = [\n",
    "    {\n",
    "        \"text\": \"Natural language processing (NLP) is a subfield of artificial intelligence. It focuses on interaction between computers and human language. NLP involves developing algorithms that can understand text. These algorithms can interpret human language patterns. They can also generate human-like text responses. Modern NLP uses deep learning techniques. Transformers have revolutionized the field. Applications include translation, summarization, and chatbots.\",\n",
    "        \"doc_id\": \"doc_long_1\",\n",
    "        \"source\": \"AI_encyclopedia\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Machine learning automates analytical model building. It uses algorithms that learn from data iteratively. Computers find hidden insights automatically. No explicit programming is needed for pattern discovery. Supervised learning uses labeled training data. Unsupervised learning finds patterns in unlabeled data. Reinforcement learning learns through trial and error. Deep learning uses neural networks with multiple layers.\",\n",
    "        \"doc_id\": \"doc_long_2\", \n",
    "        \"source\": \"ML_handbook\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create a new dataset with longer documents for chunking demonstration\n",
    "longer_df = pd.DataFrame(longer_docs)\n",
    "chunking_dataset = DocumentDataset.from_pandas(longer_df, backend=backend)\n",
    "\n",
    "print(f\"üìÑ Created dataset with {len(longer_docs)} longer documents for chunking\")\n",
    "print(f\"üìù Sample document length: {len(longer_docs[0]['text'])} characters\")\n",
    "\n",
    "# Split documents by sentences (using period as separator)\n",
    "print(\"\\nüî™ Splitting documents into smaller chunks...\")\n",
    "splitter = DocumentSplitter(\n",
    "    separator=\".\", \n",
    "    text_field=\"text\",\n",
    "    segment_id_field=\"segment_id\"\n",
    ")\n",
    "\n",
    "chunked_dataset = splitter(chunking_dataset)\n",
    "print(f\"‚úÖ Document splitting complete\")\n",
    "\n",
    "# Show the results\n",
    "chunked_sample = chunked_dataset.df.compute()\n",
    "print(f\"\\nüìä Chunking results:\")\n",
    "print(f\"   - Original documents: {len(longer_docs)}\")\n",
    "print(f\"   - Total chunks created: {len(chunked_sample)}\")\n",
    "print(f\"\\nüìã Sample chunks:\")\n",
    "print(chunked_sample[['doc_id', 'segment_id', 'text']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94187c9f",
   "metadata": {},
   "source": [
    "## 5. Embedding Model Selection and Loading\n",
    "\n",
    "Now we'll configure and load an embedding model to convert our text chunks into dense vector representations. We'll use sentence-transformers which integrates well with NeMo Curator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6866fd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure embedding model settings\n",
    "print(\"ü§ñ Configuring embedding model...\")\n",
    "\n",
    "# Model configuration - using a lightweight, high-quality sentence transformer\n",
    "EMBEDDING_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "EMBEDDING_BATCH_SIZE = 128  # Adjust based on your GPU memory\n",
    "EMBEDDING_DIM = 384  # Dimension of the all-MiniLM-L6-v2 model\n",
    "\n",
    "print(f\"üìã Embedding Configuration:\")\n",
    "print(f\"   - Model: {EMBEDDING_MODEL}\")\n",
    "print(f\"   - Batch size: {EMBEDDING_BATCH_SIZE}\")\n",
    "print(f\"   - Embedding dimension: {EMBEDDING_DIM}\")\n",
    "print(f\"   - GPU acceleration: {USE_GPU}\")\n",
    "\n",
    "# Test embedding model loading\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    \n",
    "    print(f\"\\nüîÑ Loading embedding model...\")\n",
    "    test_model = SentenceTransformer(EMBEDDING_MODEL)\n",
    "    \n",
    "    # Test with a sample text\n",
    "    test_text = \"This is a test sentence for embedding generation.\"\n",
    "    test_embedding = test_model.encode([test_text])\n",
    "    \n",
    "    print(f\"‚úÖ Model loaded successfully!\")\n",
    "    print(f\"üìä Test embedding shape: {test_embedding.shape}\")\n",
    "    print(f\"üî¢ Sample embedding values: {test_embedding[0][:5]}...\")\n",
    "    \n",
    "    # Clean up test model\n",
    "    del test_model\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading embedding model: {e}\")\n",
    "    print(\"Please ensure sentence-transformers is installed: pip install sentence-transformers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f47e434",
   "metadata": {},
   "source": [
    "## 6. Batch Embedding Generation\n",
    "\n",
    "Now we'll use NeMo Curator's EmbeddingCreator to generate embeddings for all our text chunks at scale. This module handles distributed processing, GPU acceleration, and memory management automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c529696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up embedding generation using NeMo Curator's EmbeddingCreator\n",
    "print(\"üöÄ Starting distributed embedding generation...\")\n",
    "\n",
    "# Create output directory for embeddings\n",
    "embeddings_dir = data_dir / \"embeddings\"\n",
    "embeddings_dir.mkdir(exist_ok=True)\n",
    "\n",
    "try:\n",
    "    # Initialize the EmbeddingCreator\n",
    "    embedding_creator = EmbeddingCreator(\n",
    "        model_name_or_path=EMBEDDING_MODEL,\n",
    "        text_field=\"text\",\n",
    "        embedding_field=\"embeddings\",\n",
    "        batch_size=EMBEDDING_BATCH_SIZE,\n",
    "        embedding_save_loc=str(embeddings_dir),\n",
    "        write_embeddings_to_disk=True,\n",
    "        id_field=\"doc_id\"\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ EmbeddingCreator initialized\")\n",
    "    print(f\"   - Input field: {embedding_creator.text_field}\")\n",
    "    print(f\"   - Output field: {embedding_creator.embedding_field}\")\n",
    "    print(f\"   - Batch size: {embedding_creator.batch_size}\")\n",
    "    \n",
    "    # For this tutorial, let's use our normalized dataset (smaller for demonstration)\n",
    "    print(f\"\\nüîÑ Generating embeddings for {len(normalized_dataset.df)} documents...\")\n",
    "    \n",
    "    # Generate embeddings\n",
    "    start_time = time.time()\n",
    "    dataset_with_embeddings = embedding_creator(normalized_dataset)\n",
    "    embedding_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"‚úÖ Embedding generation complete!\")\n",
    "    print(f\"‚è±Ô∏è  Time taken: {embedding_time:.2f} seconds\")\n",
    "    \n",
    "    # Inspect the results\n",
    "    embeddings_sample = dataset_with_embeddings.df.head(3).compute()\n",
    "    print(f\"\\nüìä Results preview:\")\n",
    "    print(f\"   - Total documents with embeddings: {len(dataset_with_embeddings.df)}\")\n",
    "    print(f\"   - Columns: {list(embeddings_sample.columns)}\")\n",
    "    \n",
    "    # Check embedding shape\n",
    "    if 'embeddings' in embeddings_sample.columns:\n",
    "        sample_embedding = embeddings_sample['embeddings'].iloc[0]\n",
    "        print(f\"   - Embedding shape: {np.array(sample_embedding).shape}\")\n",
    "        print(f\"   - Sample embedding values: {np.array(sample_embedding)[:5]}...\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during embedding generation: {e}\")\n",
    "    print(\"üìù Note: EmbeddingCreator requires GPU setup. Using alternative approach...\")\n",
    "    \n",
    "    # Alternative: Generate embeddings manually for tutorial purposes\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    \n",
    "    model = SentenceTransformer(EMBEDDING_MODEL)\n",
    "    \n",
    "    # Get text data\n",
    "    text_data = normalized_dataset.df['text'].compute().tolist()\n",
    "    print(f\"üîÑ Generating embeddings for {len(text_data)} texts using fallback method...\")\n",
    "    \n",
    "    # Generate embeddings in batches\n",
    "    all_embeddings = []\n",
    "    for i in range(0, len(text_data), EMBEDDING_BATCH_SIZE):\n",
    "        batch_texts = text_data[i:i+EMBEDDING_BATCH_SIZE]\n",
    "        batch_embeddings = model.encode(batch_texts)\n",
    "        all_embeddings.extend(batch_embeddings.tolist())\n",
    "    \n",
    "    # Add embeddings to dataset\n",
    "    df_with_embeddings = normalized_dataset.df.compute()\n",
    "    df_with_embeddings['embeddings'] = all_embeddings\n",
    "    dataset_with_embeddings = DocumentDataset.from_pandas(df_with_embeddings, backend=backend)\n",
    "    \n",
    "    print(f\"‚úÖ Fallback embedding generation complete!\")\n",
    "    print(f\"üìä Generated {len(all_embeddings)} embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b941ab",
   "metadata": {},
   "source": [
    "## 7. Vector Storage Setup and Configuration\n",
    "\n",
    "With our embeddings generated, we need to store them in a vector database for efficient similarity search and retrieval. We'll demonstrate multiple vector storage options including FAISS and ChromaDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a63a94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up vector storage using FAISS\n",
    "print(\"üóÑÔ∏è  Setting up vector storage with FAISS...\")\n",
    "\n",
    "try:\n",
    "    import faiss\n",
    "    faiss_available = True\n",
    "    print(\"‚úÖ FAISS available\")\n",
    "except ImportError:\n",
    "    faiss_available = False\n",
    "    print(\"‚ö†Ô∏è  FAISS not available. Install with: pip install faiss-gpu (for GPU) or pip install faiss-cpu\")\n",
    "\n",
    "if faiss_available:\n",
    "    # Extract embeddings and metadata\n",
    "    df_with_emb = dataset_with_embeddings.df.compute()\n",
    "    embeddings_array = np.array(df_with_emb['embeddings'].tolist()).astype('float32')\n",
    "    \n",
    "    print(f\"üìä Preparing FAISS index:\")\n",
    "    print(f\"   - Number of vectors: {embeddings_array.shape[0]}\")\n",
    "    print(f\"   - Vector dimension: {embeddings_array.shape[1]}\")\n",
    "    \n",
    "    # Create FAISS index\n",
    "    dimension = embeddings_array.shape[1]\n",
    "    \n",
    "    # Use L2 distance for similarity (can also use IP for inner product)\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    \n",
    "    # Optionally use GPU acceleration if available\n",
    "    if USE_GPU and hasattr(faiss, 'StandardGpuResources'):\n",
    "        try:\n",
    "            res = faiss.StandardGpuResources()\n",
    "            index = faiss.index_cpu_to_gpu(res, 0, index)\n",
    "            print(\"üöÄ Using GPU-accelerated FAISS index\")\n",
    "        except:\n",
    "            print(\"‚ö†Ô∏è  GPU FAISS failed, using CPU index\")\n",
    "    \n",
    "    # Add vectors to index\n",
    "    print(\"üîÑ Adding vectors to FAISS index...\")\n",
    "    index.add(embeddings_array)\n",
    "    \n",
    "    print(f\"‚úÖ FAISS index created successfully!\")\n",
    "    print(f\"   - Index type: {type(index)}\")\n",
    "    print(f\"   - Total vectors: {index.ntotal}\")\n",
    "    print(f\"   - Is trained: {index.is_trained}\")\n",
    "    \n",
    "    # Save the index to disk\n",
    "    faiss_index_path = data_dir / \"faiss_index.bin\"\n",
    "    if hasattr(index, 'cpu_index'):  # GPU index\n",
    "        faiss.write_index(index.cpu_index, str(faiss_index_path))\n",
    "    else:  # CPU index\n",
    "        faiss.write_index(index, str(faiss_index_path))\n",
    "    \n",
    "    print(f\"üíæ FAISS index saved to: {faiss_index_path}\")\n",
    "    \n",
    "    # Save metadata mapping\n",
    "    metadata_mapping = df_with_emb[['doc_id', 'text', 'source', 'category']].reset_index(drop=True)\n",
    "    metadata_path = data_dir / \"metadata_mapping.parquet\"\n",
    "    metadata_mapping.to_parquet(metadata_path)\n",
    "    \n",
    "    print(f\"üíæ Metadata mapping saved to: {metadata_path}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Skipping FAISS setup due to missing dependency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcef5641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Set up ChromaDB vector database\n",
    "print(\"\\nüîÆ Setting up alternative vector storage with ChromaDB...\")\n",
    "\n",
    "try:\n",
    "    import chromadb\n",
    "    from chromadb.config import Settings\n",
    "    \n",
    "    # Create ChromaDB client\n",
    "    chroma_client = chromadb.Client(Settings(\n",
    "        persist_directory=str(data_dir / \"chroma_db\"),\n",
    "        anonymized_telemetry=False\n",
    "    ))\n",
    "    \n",
    "    # Create or get collection\n",
    "    collection_name = \"tutorial_embeddings\"\n",
    "    try:\n",
    "        collection = chroma_client.create_collection(name=collection_name)\n",
    "        print(f\"‚úÖ Created new ChromaDB collection: {collection_name}\")\n",
    "    except:\n",
    "        collection = chroma_client.get_collection(name=collection_name)\n",
    "        print(f\"‚úÖ Using existing ChromaDB collection: {collection_name}\")\n",
    "    \n",
    "    # Prepare data for ChromaDB\n",
    "    df_with_emb = dataset_with_embeddings.df.compute()\n",
    "    \n",
    "    # ChromaDB requires specific data format\n",
    "    documents = df_with_emb['text'].tolist()\n",
    "    embeddings = [emb.tolist() if isinstance(emb, np.ndarray) else emb for emb in df_with_emb['embeddings']]\n",
    "    ids = [str(i) for i in range(len(documents))]\n",
    "    metadatas = [\n",
    "        {\n",
    "            \"doc_id\": row['doc_id'],\n",
    "            \"source\": row['source'],\n",
    "            \"category\": row['category']\n",
    "        }\n",
    "        for _, row in df_with_emb.iterrows()\n",
    "    ]\n",
    "    \n",
    "    print(f\"üîÑ Adding {len(documents)} documents to ChromaDB...\")\n",
    "    \n",
    "    # Add to ChromaDB collection\n",
    "    collection.add(\n",
    "        embeddings=embeddings,\n",
    "        documents=documents,\n",
    "        metadatas=metadatas,\n",
    "        ids=ids\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ ChromaDB setup complete!\")\n",
    "    print(f\"   - Collection: {collection_name}\")\n",
    "    print(f\"   - Documents stored: {collection.count()}\")\n",
    "    print(f\"   - Persist directory: {data_dir / 'chroma_db'}\")\n",
    "    \n",
    "    chromadb_available = True\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è  ChromaDB not available. Install with: pip install chromadb\")\n",
    "    chromadb_available = False\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error setting up ChromaDB: {e}\")\n",
    "    chromadb_available = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50dc26f",
   "metadata": {},
   "source": [
    "## 8. Indexing and Metadata Management\n",
    "\n",
    "Effective metadata management is crucial for retrieval systems. We need to efficiently store and retrieve both the vector embeddings and their associated metadata (document IDs, sources, categories, etc.)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
